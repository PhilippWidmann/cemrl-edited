{
    "env_name": "metaworld-ml1-reach-line-action-restricted-distReward",
    "env_params": {
        "n_train_tasks": 50,
        "n_eval_tasks": 50,
        "use_normalized_env": false,
        "ml10or45": "reach-special",
        "base_task": "reach-v2-line-action-restricted-distReward",
        "state_reconstruction_clip": 12,
        "use_state_decoder": false
    },
    "algo_params": {
        "use_data_normalization": false,
        "exploration_agent": "ensemble_urlb_smm",
        "exploration_pretraining_steps": 20000,
        "exploration_ensemble_agents": 3,
        "sac_uses_exploration_data": true,
        "exploration_by_probability": true,
        "use_fixed_seeding": true,
        "seed": 0,
        "time_steps": 30,
        "decoder_time_window": [-Infinity, Infinity],
        "latent_size": 1,
        "sac_layer_size": 150,
        "num_train_epochs": 251,
        "num_train_tasks_per_episode": 10,
        "num_trajectories_per_task": 1,
        "num_exploration_trajectories_per_task": 2,
        "num_transitions_per_episode": 100,
        "max_path_length": 100
    },
    "reconstruction_params": {
        "reconstruct_all_timesteps": true,
        "prior_mode": "fixedOnY",
        "prior_sigma": 0.5,
        "num_classes": 1,
        "lr_encoder": 0.0003,
        "lr_decoder": 0.0003,
        "alpha_kl_z": 0.001,
        "beta_kl_y": 0.001,
        "net_complex_enc_dec": 5.0
    }
}
